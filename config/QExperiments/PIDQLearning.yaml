kp: [1, 1, 1, 1, 1]
kd: [0, 0.002, 0.004, 0.006, 0.008]
ki: [0, 0, 0, 0, 0]
alpha: [0.05, 0.05, 0.05, 0.05, 0.05]
beta: [0.95, 0.95, 0.95, 0.95, 0.95]
decay: [0.99999, 0.99999, 0.99999, 0.99999, 0.99999]
gamma: 0.99

agent_name: [Q learning, Q learning, Q learning, Q learning, Q learning]

env: chain walk
num_iterations: 30000
norm: fro
get_optimal: True # Get the optimal parameters from the database
compute_optimal: True  # Run a grid search. When recompute_optimal is false, we don't run a grid search if the optimal parameters are in the database already
recompute_optimal: True  # If compute_optimal is True, run a grid search even if the optimal parameters are in the database
num_repeats: 20

follow_trajectory: False

seed: 8483814
hydra:
  run:
    dir: ${oc.env:OUTPUT_DIR,./outputs}/${hydra.job.config_name}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  job:
    chdir: True